# Comprehensive Explanation of GMRES with Detailed Equations

The **Generalized Minimal Residual Method (GMRES)** is an iterative algorithm designed to solve the linear system $A \mathbf{x} = \mathbf{b}$, where $A \in \mathbb{R}^{m \times m}$ and $\mathbf{b} \in \mathbb{R}^m$. It is particularly effective for large, sparse, or non-symmetric systems. Instead of directly computing $\mathbf{x} = A^{-1} \mathbf{b}$, GMRES approximates the solution iteratively by minimizing the residual $\mathbf{r}_n = \mathbf{b} - A \mathbf{x}_n$. This approach aims to balance computational efficiency and numerical stability.

---

## Minimizing the Residual
The residual at each iteration is defined as:

$$
\mathbf{r}_n = \mathbf{b} - A \mathbf{x}_n,
$$

where $\mathbf{x}_n$ is the approximate solution in the $n$-th iteration. GMRES minimizes the norm of this residual, $\|\mathbf{r}_n\|$, over the Krylov subspace $\mathcal{K}_n$, which is spanned by the initial residual and the powers of $A$ applied to $\mathbf{b}$:

$$
\mathcal{K}_n = \text{span}(\mathbf{b}, A\mathbf{b}, A^2\mathbf{b}, \ldots, A^{n-1}\mathbf{b}).
$$

The approximation $\mathbf{x}_n$ is expressed as:

$$
\mathbf{x}_n = \mathbf{x}_0 + \mathcal{K}_n \mathbf{C},
$$

where $\mathbf{C}$ is a vector of coefficients that is chosen to minimize $\|\mathbf{r}_n\|$. This can be written explicitly as:

$$
\mathbf{x}_n = \mathcal{K}_n \mathbf{C}, \quad \text{with} \quad \|\mathbf{r}_n\| = \|\mathbf{b} - A \mathbf{x}_n\|.
$$

---

## Matrix Representation of the Krylov Subspace
The Krylov subspace can be represented as:

$$
A \mathcal{K}_n = \begin{bmatrix}
\mathbf{b} & A \mathbf{b} & A^2 \mathbf{b} & \ldots & A^{n-1} \mathbf{b}
\end{bmatrix}.
$$

To ensure numerical stability and efficiency, this basis is orthonormalized during the computation.

---

## Arnoldi Iteration for Orthonormalization
The Arnoldi process is used to build an orthonormal basis $Q_n$ for the Krylov subspace. This leads to the relation:

$$
A Q_n = Q_{n+1} H_n,
$$

where:
- $Q_n \in \mathbb{R}^{m \times n}$ is an orthonormal matrix,
- $Q_{n+1} \in \mathbb{R}^{m \times (n+1)}$,
- $H_n \in \mathbb{R}^{(n+1) \times n}$ is an upper Hessenberg matrix.

---

## What Is a Hessenberg Matrix?
A Hessenberg matrix is a nearly triangular matrix, meaning that it has zeros below the first subdiagonal. For example, an upper Hessenberg matrix has the form:

$$
H_n = 
\begin{bmatrix}
h_{11} & h_{12} & h_{13} & \cdots & h_{1n} \\
h_{21} & h_{22} & h_{23} & \cdots & h_{2n} \\
0 & h_{32} & h_{33} & \cdots & h_{3n} \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & 0 & \cdots & h_{n,n-1} & h_{nn}
\end{bmatrix}.
$$

This structure arises naturally in the Arnoldi process and reduces computational complexity while preserving important information about the matrix $A$.

---

## Reformulating the Problem
Using the orthonormal basis $Q_n$, the approximate solution $\mathbf{x}_n$ can be written as:

$$
\mathbf{x}_n = Q_n \mathbf{y},
$$

where $\mathbf{y} \in \mathbb{R}^n$ is the new coefficient vector. Substituting this into the residual minimization problem, we get:

$$
\min \| A Q_n \mathbf{y} - \mathbf{b} \|.
$$

After orthonormalization through the Arnoldi process, this simplifies to:

$$
\min \| H_n \mathbf{y} - \|\mathbf{b}\| \mathbf{e}_1 \|,
$$

where $\mathbf{e}_1$ is the first standard basis vector.

---

## Optimization Goals
The main optimization goal in GMRES is:

$$
\min \| A Q_n \mathbf{y} - \mathbf{b} \|.
$$

This residual is projected onto the Krylov subspace, and the solution is adjusted iteratively to minimize it. The reduced problem simplifies computations significantly while maintaining accuracy.

---

## Practical Steps in GMRES
1. **Initialize**: Start with the first direction $\mathbf{q}_1 = \frac{\mathbf{b}}{\|\mathbf{b}\|}$.
2. **Arnoldi Iteration**:
   - Compute $A Q_n = Q_{n+1} H_n$ iteratively.
   - Build the Hessenberg matrix $H_n$, which captures the reduced system dynamics.
3. **Solve the Least Squares Problem**:
   - Minimize:
     $$
     \min \| H_n \mathbf{y} - \|\mathbf{b}\| \mathbf{e}_1 \|.
     $$
4. **Compute the Solution**:
   - Use the solution $\mathbf{y}$ to approximate:
     $$
     \mathbf{x}_n = Q_n \mathbf{y}.
     $$

---

## Issues and Practical Considerations
One challenge with GMRES is that the Krylov subspace grows with each iteration, leading to increased computational costs and memory usage. To address this, a **restart mechanism** is often used. After a fixed number of iterations, the algorithm resets, using the current approximation $\mathbf{x}_n$ as the new starting point.

---

## Summary
GMRES effectively solves large, sparse, or non-symmetric systems by iteratively minimizing the residual in a reduced Krylov subspace. By leveraging the Arnoldi iteration to build an orthonormal basis, GMRES ensures numerical stability and efficiency. The reformulation of the problem into a smaller least squares optimization using the Hessenberg matrix $H_n$ reduces computational complexity. The Hessenberg matrix's structure as a nearly triangular matrix simplifies computations while preserving essential system properties. Through these techniques, GMRES achieves robust performance for systems where direct solvers are impractical. Its flexibility, including the use of restarts, makes it a powerful tool for scientific and engineering applications.
