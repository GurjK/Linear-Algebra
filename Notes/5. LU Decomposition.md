
A common problem to solve is Ax = b. Inuitively, the common way for solving for x, would be to just invert A and solve $x=A^{-1}b$ but as mentioned in previous lessons that is numerically inefficient. A more efficient way of solving this would be to transform A into a lower traingular matrix, L and upper triangular matrix U. Then proceeding to solve this. But first we must understand forward and backward substitution to fully solve Ax=b using LU decomposition

## Forward Substitution

Say we have the system defined as $Ly=b$ where the goal is to solve for b and L is a lower triangular matrix. In order to efficiently solve for this instead of computing $L^{-1}$ we perform the following.

### Algorithm for Forward Substitution
- L = n x n square matrix
- b = n x 1 vector 
- y= n x 1 vector

$$
Ly = 
\begin{bmatrix}
l_{1,1} & 0 \\
l_{2,1} & l_{2,2}
\end{bmatrix} \begin{bmatrix} y_1 \\ y_2 \end{bmatrix} = \begin{bmatrix} b_1 \\ b_2 \end{bmatrix} = b
$$
1. $$b_1 = b_{1} / l_{1,1}$$
2. $$b_i = \frac{(b_i - \sum_{j=1}^{i-1}l_{ij}x{j})}{l_{ii}}$$
3. b is now the solution, y to Ly=b

### Example of Forward Substitution 

## Example Walkthrough

Given:
$$
L = \begin{bmatrix}
2 & 0 & 0 \\
3 & 1 & 0 \\
1 & -1 & 1
\end{bmatrix}, \quad
b = \begin{bmatrix}
4 \\ 5 \\ 6
\end{bmatrix}.
$$


### Step-by-Step Updates:
1. Compute ( b[1] ):
$$
b[1] = \frac{b[1]}{L[1, 1]} = \frac{4}{2} = 2.
$$

2. Compute ( b[2]):
$$
b[2] = \frac{b[2] - L[2, 1] \cdot b[1]}{L[2, 2]} = \frac{5 - 3 \cdot 2}{1} = -1.
$$

3. Compute (b[3]):
$$
b[3] = \frac{b[3] - (L[3, 1] \cdot b[1] + L[3, 2] \cdot b[2])}{L[3, 3]} = \frac{6 - (1 \cdot 2 + (-1) \cdot -1)}{1} = 3.
$$

### Solution:
$$
x = b = \begin{bmatrix} 2 \\ -1 \\ 3 \end{bmatrix}.
$$

## Backward Substitution

Now say we have an upper triangular matrix U, a vector x, and a vector y, $Ux=y$. This can be solved without inverting the matrix by performing backward substitution.

$$
Ux = 
\begin{bmatrix}
u_{1,1} & u_{1,2} \\
u_{2,1} & 0
\end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} y_1 \\ y_2 \end{bmatrix} = y
$$
### Algorithm for Backward Substitution
- U = n x n square matrix
- x = n x 1 vector 
- y= n x 1 vector

1. $$y(n) = y(n) / U(n,n) $$
2. $$ y(i) = \frac{y(i) - \sum_{j=i+1}^{n} u_{ij}x_{j}}{u_{ii}} $$
3. y is the solution overwritten to x for  Ux=y

### Example of Backward Substitution

## Example Walkthrough

Given:
$$
U = \begin{bmatrix}
2 & 1 & -1 \\
0 & 3 & 2 \\
0 & 0 & 1
\end{bmatrix}, \quad
y = \begin{bmatrix}
5 \\ 8 \\ 3
\end{bmatrix}.
$$

### Step-by-Step Updates:
1. Compute \( y(n) \):
$$
y(3) = \frac{y(3)}{U(3, 3)} = \frac{3}{1} = 3.
$$

2. Compute \( y(n-1) \):
$$
y(2) = \frac{y(2) - \sum_{j=3}^{3} U(2, j) y(j)}{U(2, 2)} = \frac{8 - (2 \cdot 3)}{3} = \frac{2}{3}.
$$

3. Compute \( y(i) \) for \( i = 1 \):
$$
y(1) = \frac{y(1) - \sum_{j=2}^{3} U(1, j) y(j)}{U(1, 1)} = \frac{5 - (U(1, 2) \cdot y(2) + U(1, 3) \cdot y(3))}{U(1, 1)}.
$$

Substitute values:
$$
y(1) = \frac{5 - \left(1 \cdot \frac{2}{3} + (-1) \cdot 3\right)}{2}.
$$

Simplify:
$$
y(1) = \frac{5 - \left(\frac{2}{3} - 3\right)}{2} = \frac{5 - (-\frac{7}{3})}{2} = \frac{\frac{15}{3} + \frac{7}{3}}{2} = \frac{\frac{22}{3}}{2} = \frac{11}{3}.
$$

### Final Solution:
$$
y = \begin{bmatrix}
\frac{11}{3} \\ \frac{2}{3} \\ 3
\end{bmatrix}.
$$

## Converting A to LU

Now We have seen how efficient it is to solve using triangular matrices. Now we need to understand how to actually get from Ax=b to LUx=b

Steps:
1. Ax =b
2. LUx =b
3. Let y = Ux
4. Solve Ly=b for y using Forward Substitution
5. Solve Ux =y for x using Backward Substituion
### Converting A to LU through Gauss Transforms

In order to Solve the equation we first need to understand how to convert the matrix A to LU.

Gaussian elimination is the process of converting a matrix A to U through elimination. The idea is to you multipliers of a row and add them to another row to turn certain entries in that row into 0s, so it becomes and upper matrix. These multiplies that we are storing are actually the basis of the second matrix that we need to compute L. 

L is the matrix of the multipliers applied to U through row operations and the diagonals of the matrix are all 1s. 

1. **Purpose of \( L[i, j] \):** - $L[i, j]$ stores the **multiplier** used during Gaussian elimination to eliminate $U[i, j]$ below the pivot. 

2. **Steps for Each Column:** - For each column $k$: - Use the row operation $R_i \to R_i - m_{ij} R_j$, where $j$ is the current pivot row and $i > j$. - Store the multiplier $m_{ij} = \frac{U[i, j]}{U[j, j]}$ in $L[i, j]$.

This process in know as Gaussian Elimination.

### LU Decomposition without Pivoting

# LU Decomposition Without Pivoting Using Row Operations

Let:
$$
A = \begin{bmatrix}
2 & 3 & 1 \\
4 & 7 & 3 \\
6 & 18 & 5
\end{bmatrix}.
$$

We want to decompose \( A \) into \( L \) (lower triangular matrix) and \( U \) (upper triangular matrix) such that:
$$
A = LU.
$$

---

## Step 1: Initialize

Start with \( L = I \) (identity matrix) and \( U = A \):
$$
L = \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}, \quad
U = \begin{bmatrix}
2 & 3 & 1 \\
4 & 7 & 3 \\
6 & 18 & 5
\end{bmatrix}.
$$

---

## Step 2: Eliminate Below the First Pivot (\( U[1, 1] = 2 \)) Using Row Operations

- To eliminate \( U[2, 1] \) (\( 4 \)), perform the row operation:
  $$
  R_2 \to R_2 - 2R_1.
  $$
  Here, the multiplier is:
  $$
  m_{21} = \frac{U[2, 1]}{U[1, 1]} = \frac{4}{2} = 2.
  $$
  The updated row \( R_2 \) becomes:
  $$
  R_2 = \begin{bmatrix} 4 & 7 & 3 \end{bmatrix} - 2 \cdot \begin{bmatrix} 2 & 3 & 1 \end{bmatrix} = \begin{bmatrix} 0 & 1 & 1 \end{bmatrix}.
  $$

- To eliminate \( U[3, 1] \) (\( 6 \)), perform the row operation:
  $$
  R_3 \to R_3 - 3R_1.
  $$
  Here, the multiplier is:
  $$
  m_{31} = \frac{U[3, 1]}{U[1, 1]} = \frac{6}{2} = 3.
  $$
  The updated row \( R_3 \) becomes:
  $$
  R_3 = \begin{bmatrix} 6 & 18 & 5 \end{bmatrix} - 3 \cdot \begin{bmatrix} 2 & 3 & 1 \end{bmatrix} = \begin{bmatrix} 0 & 9 & 2 \end{bmatrix}.
  $$

- Update \( L \): Each multiplier \( m_{ij} \) is stored in \( L[i, j] \):
  $$
  L[2, 1] = m_{21} = 2, \quad L[3, 1] = m_{31} = 3.
  $$

**Updated Matrices:**
$$
L = \begin{bmatrix}
1 & 0 & 0 \\
2 & 1 & 0 \\
3 & 0 & 1
\end{bmatrix}, \quad
U = \begin{bmatrix}
2 & 3 & 1 \\
0 & 1 & 1 \\
0 & 9 & 2
\end{bmatrix}.
$$

---

## Step 3: Eliminate Below the Second Pivot (\( U[2, 2] = 1 \)) Using Row Operations

- To eliminate \( U[3, 2] \) (\( 9 \)), perform the row operation:
  $$
  R_3 \to R_3 - 9R_2.
  $$
  Here, the multiplier is:
  $$
  m_{32} = \frac{U[3, 2]}{U[2, 2]} = \frac{9}{1} = 9.
  $$
  The updated row \( R_3 \) becomes:
  $$
  R_3 = \begin{bmatrix} 0 & 9 & 2 \end{bmatrix} - 9 \cdot \begin{bmatrix} 0 & 1 & 1 \end{bmatrix} = \begin{bmatrix} 0 & 0 & -7 \end{bmatrix}.
  $$

- Update \( L \): The multiplier \( m_{32} = 9 \) is stored in \( L[3, 2] \):
  $$
  L[3, 2] = m_{32} = 9.
  $$

**Updated Matrices:**
$$
L = \begin{bmatrix}
1 & 0 & 0 \\
2 & 1 & 0 \\
3 & 9 & 1
\end{bmatrix}, \quad
U = \begin{bmatrix}
2 & 3 & 1 \\
0 & 1 & 1 \\
0 & 0 & -7
\end{bmatrix}.
$$

---

## Final Result

- \( L \) (Lower Triangular Matrix):
  $$
  L = \begin{bmatrix}
  1 & 0 & 0 \\
  2 & 1 & 0 \\
  3 & 9 & 1
  \end{bmatrix}.
  $$

- \( U \) (Upper Triangular Matrix):
  $$
  U = \begin{bmatrix}
  2 & 3 & 1 \\
  0 & 1 & 1 \\
  0 & 0 & -7
  \end{bmatrix}.
  $$

---

## Issues with LU Decomposition without Pivoting

In this example it isn't highlighted since this was a well-behaved question but there are issues that can arise in these types of problems:

# Issues with LU Decomposition Without Pivoting

LU decomposition without pivoting can lead to significant numerical and computational problems:

---

## Key Issues

1. **Zero or Small Pivot Elements**
   - Zero pivots cause division by zero, while small pivots lead to large multipliers, amplifying numerical errors.

2. **Numerical Instability**
   - Sensitive to row order, with small pivots causing significant rounding errors due to finite precision.

3. **Ill-Conditioned Matrices**
   - High condition numbers amplify small errors, producing inaccurate results.
	   - Condition Number
		   - Quantifies the sensitivity of the Ax=b problem. The condition number is the Fréchet derivative, normalized, which measures how small perturbations in A affect $A^{−1}$.
		   - it measures the sensitivity of the solution x to small perturbations in A or b


---

## Problems That Arise

1. **Inaccurate Solutions**
   - The computed solution $\hat{x}$ can deviate significantly from the true solution x.

2. **Breakdown for Singular or Nearly Singular Matrices**
   - Division by small or zero pivots leads to failure.

3. **Error Propagation**
   - Errors in elimination propagate through \( L \) and \( U \), corrupting the results.

4. **Numerical Inefficiency**
   - Instability makes it unsuitable for practical applications.

## Pivoting

In order to account for and reduce the issues listed above there is a method called **pivoting** which is performed anything is done. The main premise behind pivoting is to swap rows and columns such that the pivots in each column aren't small thus resulting in smaller number in L and U. In addition.

In Pivoting it is important to understanding how these operations are performed, such that the row and columns swaps are peformed as a matrix multiplication, for that reason we introduce a Permutation matrix, P. P is a permutation matrix that starts as the identity matrix and then is permutated based on the row swaps formed. 

While in these example our Permutation Matrix is swapped cumulatively it is another way of expressing each permutation as its own operation, $M_I$ and expressing it as a matrix multiplication.

$$
P = M_k*M_{k-1}*...*M_{1}
$$
where $M_i$ is each row swap

There are 3 types of pivoting techniques that are going to be discussed slightly:
1. Partial Pivoting
	-Swapping the rows such that the pivot is the large absolute value term in each column at each step
	-This is the default method usually since its cost is worth its numerical stability

	Steps:
		1. Solve PA = LU
		2. For each step k
			1. Find the largest value in the column k  
			2. Swap that row k and the row contain the largest value
			3. Perform Gaussian Elimination
			4. Store multipliers in L
		3. Compute $Pb=b^{'}$
		4. Solve $Lz=b^{'}$ with forward substitution
		5. Solve $Uy =z$ with backward substitution
2. Complete Pivoting
	-row and columns swaps are performed to select the largest absolute value term in the entire remaining submatrix and ensure that it is the pivot
	-Computationally expensive since it requires significant floating point operations due to the 2 dimensional search at each stage.
	
	Steps:
	1. Solve $PAQ^{T} = LU$
		1. P is row permutation matrix 
		2. Q is column permutation matrix
	2. For each step k
		1. Search remaining submatrix for largest value  
		2. Swap that row k and column containing largest value and update P and Q
		3. Perform Gaussian Elimination
		4. Store multipliers in L
	3. Compute $Pb=b^{'}$
	4. Solve $Lz=b^{'}$ with forward substitution
	5. Solve $Uy =z$ with backward substitution
	6. Compute $x=Q^Ty$'

3. Rook Pivoting
	-Alternatively to Complete Pivoting, Rook Pivoting looks for a pivot that is the maximum value in both its row and column only, not the entire submatrix
	-Has the same overhead as Partial Pivoting except for in extreme case scenarios but it has the same reliability of Complete Pivoting

	Steps:
		1. Solve $PAQ^{T} = LU$
			1. P is row permutation matrix 
			2. Q is column permutation matrix
		2. For each step k
			1. Search current column k for largest absolute value  
			2. Check if its the largest value in the corresponding row as well, if it is not move to the column of this value
			3. Stop when largest value in the row and column coincides
			4. Swap the row and column and update P and Q
			5. Perform Gaussian Elimination
			6. Store multipliers in L
		3. Compute $Pb=b^{'}$
		4. Solve $Lz=b^{'}$ with forward substitution
		5. Solve $Uy =z$ with backward substitution
		6. Compute $x=Q^Ty$'


#### Example of Partial Pivoting for LU Decomposition
>Let 
>$$
A=\begin{bmatrix}
3 & 17 & 10 \\
2 & 4 & -2 \\
6 & 18 & -12
\end{bmatrix}
$$
>Then we will perform PA = LU using partial pivoting on this.
>First looking at the first column we see that $$max(3,2,6)=6$$
>So we swap $R3$ and $R1$   giving use the P and U
>$$
  P = \begin{bmatrix}
  0 & 0 & 1 \\
  0 & 1 & 0 \\
  1 & 0 & 0
  \end{bmatrix}, 
U=\begin{bmatrix}
6 & 18 & -12 \\
2 & 4 & -2 \\
3 & 17 & 10
\end{bmatrix}
  $$
  >Now performing gaussian elimination where 
  >$$R_2 \to R_2 - \frac{1}{3} *R_1, R_3 \to R_3 - \frac{1}{2}*R_1$$
  Gives us 
$$
  U=\begin{bmatrix}
6 & 18 & -12 \\
0 & -2 & 2 \\
0 & 8 & 16
\end{bmatrix},
L =\begin{bmatrix}
1 & 00 & 00 \\
\frac{1}{2} & 1 & 0 \\
\frac{1}{3} & 0 & 1
\end{bmatrix}
$$
>Moving onto the second column now. We try to find the first pivot and in this case it is -2, we then determine that
$$
max(2,8) = 8
$$
>so we need to swap Row 2 and Row 3 giving us.
>$$
  P = \begin{bmatrix}
  0 & 0 & 1 \\
  1 & 0 & 0 \\
  0 & 1 & 0
  \end{bmatrix}, 
U=\begin{bmatrix}
6 & 18 & -12 \\
0 & 8 & 16 \\
0 & -2 & 2
\end{bmatrix}
$$
>The next step would be gaussian elimination where we would perform the following row operations 
>$$
R_3 \to R_3-(-\frac{1}{4})R_2
$$
>Giving use 
>$$
  U=\begin{bmatrix}
6 & 18 & -12 \\
0 & 8 & 16 \\
0 & 0 & 6
\end{bmatrix},
L =\begin{bmatrix}
1 & 0 & 0 \\
\frac{1}{2} & 1 & 0 \\
\frac{1}{3} & -\frac{1}{4} & 1
\end{bmatrix}
$$
>Now we have our final solution where $$PA = LU$$
>$$
  \begin{bmatrix}
  0 & 0 & 1 \\
  1 & 0 & 0 \\
  0 & 1 & 0
  \end{bmatrix}\begin{bmatrix}
3 & 17 & 10 \\
2 & 4 & -2 \\
6 & 18 & -12
\end{bmatrix}=
\begin{bmatrix}
1 & 0 & 0 \\
\frac{1}{2} & 1 & 0 \\
\frac{1}{3} & -\frac{1}{4} & 1
\end{bmatrix}\begin{bmatrix}
6 & 18 & -12 \\
0 & 8 & 16 \\
0 & 0 & 6
\end{bmatrix}
$$
>Note that P can also be expressed as 
>$$
P= M_2 *M_1
$$
>From which we can now proceed to solve $PAx=Pb$ = $PLUx=Pb$

#### Example of Rook Pivoting for LU Decomposition

Perform LU decomposition on A using rook pivoting

$$
A=\begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{bmatrix}
$$
First we check the first pivot $A_{1,1}$. In Column 1 the largest value is 8 in Row 3, however the largest value in Row 3 in 9 so that is our pivot. So now we
- Swap Row 1 and Row 3
- Swap Column 1 and Column 3 

$$
U = \begin{bmatrix}
9 & 8 & 7 \\
6 & 5 & 4 \\
3 & 2 & 1
\end{bmatrix}, P= \begin{bmatrix}
0 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 0
\end{bmatrix}, Q = \begin{bmatrix}
0 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 0
\end{bmatrix} 
$$
We now perform Gaussian elimination and perform the following
$$
R_2 \to R_2 -\frac{2}{3}R_1, R_3 \to R_3 - \frac{1}{3}R_1
$$
$$
U = \begin{bmatrix}
9 & 8 & 7 \\
0 & -\frac{1}{3} & -\frac{2}{3} \\
0 & -\frac{2}{3} & -\frac{4}{3}
\end{bmatrix}, L = \begin{bmatrix}
1 & 0 & 0 \\
\frac{2}{3} & 1 & 0 \\
\frac{1}{3} & 0 & 1
\end{bmatrix}
$$
Now we repeat and for column 2 where the largest value is $\frac{2}{3}$ in that column but $\frac{4}{3}$ is the largest value in that row and in its columns too so it need to be our pivot.
- Swap Row 2 and Row 3
- Swap Column 2 and 3
$$
U = \begin{bmatrix}
9 & 7 & 8 \\
0 & -\frac{4}{3} & -\frac{2}{3} \\
0 & -\frac{2}{3} & -\frac{1}{3}
\end{bmatrix}, P= \begin{bmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{bmatrix}, Q = \begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix} 
$$
We now perform Gaussian Elimination through the following Row Operations 
$$
R_3 \to R_3 - \frac{1}{2}R_2
$$
$$
U = \begin{bmatrix}
9 & 7 & 8 \\
0 & -\frac{4}{3} & -\frac{2}{3} \\
0 & 0 & 0
\end{bmatrix}, L = \begin{bmatrix}
1 & 0 & 0 \\
\frac{2}{3} & 1 & 0 \\
\frac{1}{3} & \frac{1}{2} & 1
\end{bmatrix}
$$
Giving use the Final Answer Satisfying
$$ PAQ^T = LU $$
$$
\begin{bmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{bmatrix}
\begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{bmatrix}
\begin{bmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{bmatrix} =
\begin{bmatrix}
1 & 0 & 0 \\
\frac{2}{3} & 1 & 0 \\
\frac{1}{3} & \frac{1}{2} & 1
\end{bmatrix}
\begin{bmatrix}
9 & 7 & 8 \\
0 & -\frac{4}{3} & -\frac{2}{3} \\
0 & 0 & 0
\end{bmatrix}
$$
  



