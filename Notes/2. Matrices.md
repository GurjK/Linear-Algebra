## Linear Transformations

Linear transformations are functions that map a vector in one vector space to another vector in another vector space. This is only true if the following two properties are obeyed:

$$
T(x+u) = T(x) + T(u)
$$

and 

$$
T(cu) = cT(u)
$$

where $T$ is the function, $c$ is a scalar, and $u, v$ are vectors. As long as these properties hold, the function $T$ can be defined as a **Linear Transformation**, which takes a vector from $\mathbb{R}^n$ to $\mathbb{R}^m$. The matrix $M$ represents this transformation on a vector $u$ as follows:

$$
T(u) = Mu
$$

Where $M$ is a matrix and $u$ is a vector. To understand how $M$ acts as a matrix, we need to see how $M$ represents the set of unit basis vectors.

---

## Matrices

A matrix is a set of elements combined together in a rectangular array. The size of the matrix is described by its dimensions: $m$ rows by $n$ columns. For our purposes, a matrix can represent a linear transformation such as rotation or scaling in vector spaces.

A matrix's vector columns can be decomposed into its unit basis vectors. For example, consider the matrix below:

$$
M =
\begin{bmatrix} 
1 & 2 \\ 
3 & 4
\end{bmatrix}
$$

If we take the first column of $M$, it can be decomposed as a transformation that is applied to the first unit basis vector:

$$
e_1 = \begin{bmatrix} 
1 \\ 
0
\end{bmatrix}
$$

This can be seen by applying the following matrix-vector multiplication:

$$
Me_1 = \begin{bmatrix} 
1 & 2 \\ 
3 & 4
\end{bmatrix}
\begin{bmatrix} 
1 \\ 
0
\end{bmatrix} = 
\begin{bmatrix} 
1 \cdot 1 + 2 \cdot 0 \\ 
3 \cdot 1 + 4 \cdot 0
\end{bmatrix} =
\begin{bmatrix} 
1 \\ 
3
\end{bmatrix}
$$

Similarly, for the second unit basis vector $e_2$:

$$
Me_2 = \begin{bmatrix} 
1 & 2 \\ 
3 & 4
\end{bmatrix}
\begin{bmatrix} 
0 \\ 
1
\end{bmatrix} = 
\begin{bmatrix} 
1 \cdot 0 + 2 \cdot 1 \\ 
3 \cdot 0 + 4 \cdot 1
\end{bmatrix} =
\begin{bmatrix} 
2 \\ 
4
\end{bmatrix}
$$

This shows how the unit basis vectors are transformed by $M$. A general vector $v$ can also be written as a combination of the unit basis vectors:

$$
v = \begin{bmatrix} 
v_1 \\ 
v_2
\end{bmatrix} = v_1e_1 + v_2e_2
$$

Applying the transformation $M$ to $v$:

$$
Mv = v_1Me_1 + v_2Me_2
$$

Each column of $M$ describes how the corresponding unit basis vector is transformed, creating a new transformation or coordinate system.

---

## Example: Rotation Transformation

A linear transformation of a vector in $\mathbb{R}^2$ can be described through a rotation matrix. For a rotation through an angle $\theta$, the matrix is:

$$
\begin{bmatrix}
\cos\theta & -\sin\theta \\ 
\sin\theta & \cos\theta
\end{bmatrix}
$$

When $\theta = 0$, the rotation matrix becomes the identity matrix:

$$
\begin{bmatrix}
1 & 0 \\ 
0 & 1
\end{bmatrix}
$$

---

## Example: Matrix-Vector Multiplication

To perform matrix-vector multiplication:

$$
\mathbf{w} = A \mathbf{v}, \quad \text{where}
$$

$$
A = \begin{bmatrix} 
a_{11} & a_{12} & \dots & a_{1n} \\ 
a_{21} & a_{22} & \dots & a_{2n} \\ 
\vdots & \vdots & \ddots & \vdots \\ 
a_{m1} & a_{m2} & \dots & a_{mn}
\end{bmatrix}, \quad
\mathbf{v} = \begin{bmatrix} 
v_1 \\ 
v_2 \\ 
\vdots \\ 
v_n
\end{bmatrix},
$$

$$
\mathbf{w} = \begin{bmatrix} 
\sum_{j=1}^n a_{1j} v_j \\ 
\sum_{j=1}^n a_{2j} v_j \\ 
\vdots \\ 
\sum_{j=1}^n a_{mj} v_j
\end{bmatrix}.
$$

For example:

$$
A = \begin{bmatrix} 
1 & 2 \\ 
3 & 4
\end{bmatrix}, \quad
\mathbf{v} = \begin{bmatrix} 
5 \\ 
6
\end{bmatrix}.
$$

Compute $\mathbf{w} = A \mathbf{v}$:

$$
w_1 = 1 \cdot 5 + 2 \cdot 6 = 5 + 12 = 17,
$$

$$
w_2 = 3 \cdot 5 + 4 \cdot 6 = 15 + 24 = 39,
$$

$$
\mathbf{w} = \begin{bmatrix} 
17 \\ 
39
\end{bmatrix}.
$$

---

## Matrix-Matrix Multiplication

Matrix-matrix multiplication represents applying one linear transformation after another. For $AB = M$, where:

- $A$ is an $m \times n$ matrix.
- $B$ is an $n \times p$ matrix.

The result $C = AB$ is an $m \times p$ matrix.

### Example:

$$
A = \begin{bmatrix} 
1 & 2 \\ 
3 & 4
\end{bmatrix}, \quad
B = \begin{bmatrix} 
5 & 6 \\ 
7 & 8
\end{bmatrix}.
$$

Compute AB using the dot product notation:

$$
c_{11} = 1 \cdot 5 + 2 \cdot 7 = 5 + 14 = 19,
$$

$$
c_{12} = 1 \cdot 6 + 2 \cdot 8 = 6 + 16 = 22,
$$

$$
c_{21} = 3 \cdot 5 + 4 \cdot 7 = 15 + 28 = 43,
$$

$$
c_{22} = 3 \cdot 6 + 4 \cdot 8 = 18 + 32 = 50,
$$

$$
C = \begin{bmatrix} 
19 & 22 \\ 
43 & 50
\end{bmatrix}.
$$

---

### Properties of Matrices

- $(AB)C = A(BC)$ (Associative property of matrix multiplication)
- $AB \neq BA$ (Matrix multiplication is not commutative)
- $A(B+C) = AB + AC$ (Distributive property)


## Row/Column Partitioning

A matrix can be thought of a collection of rows and columns. If we have the matrix 

$$A=
\begin{bmatrix}
1 & 2 \\
3 & 4 \\
5 & 6
\end{bmatrix}
$$

Then we can view this as 
$$
A = 
\begin{bmatrix}
r_1^T \\
r_2^T \\
r_3^T
\end{bmatrix}
$$
where 

$$
r_1^T = \begin{bmatrix} 1 & 2 \end{bmatrix}; r_2^T = \begin{bmatrix} 3 & 4 \end{bmatrix}; r_3^T = \begin{bmatrix} 5 & 6 \end{bmatrix}
$$
This would be the row partition of the matrix. The column partition would be 
$$
A = 
\begin{bmatrix}
c_1 | c_2 \\
\end{bmatrix}
$$
where 

$$
c_1 = 
\begin{bmatrix}
1 \\
3 \\
5
\end{bmatrix};
c_2 = 
\begin{bmatrix}
2 \\
4 \\
6
\end{bmatrix};
$$
## Block Matrices

An important concept for algorithms is being able to create a Matrix that is made up of Matrices, this is called a Block Matrix. For example

$$
A=\begin{bmatrix}
A_{1,1} & A_{1,2} \\
A_{2,1} & A_{2,2}
\end{bmatrix}
$$

The same operations can be applied to block matrices such as transposing them and multiplying them as long as they satisfy the row/column rule.